{"ast":null,"code":"'use strict';\n\nconst {\n  DAGLink,\n  DAGNode\n} = require('ipld-dag-pb');\n\nconst {\n  UnixFS\n} = require('ipfs-unixfs');\n\nconst Dir = require('./dir');\n\nconst persist = require('./utils/persist');\n\nconst {\n  createHAMT,\n  Bucket\n} = require('hamt-sharding');\n/**\n * @typedef {import('./types').ImporterOptions} ImporterOptions\n * @typedef {import('./types').ImportResult} ImportResult\n * @typedef {import('./types').InProgressImportResult} InProgressImportResult\n * @typedef {import('./types').BlockAPI} BlockAPI\n */\n\n/**\n * @typedef {import('./dir').DirProps} DirProps\n */\n\n\nclass DirSharded extends Dir {\n  /**\n   * @param {DirProps} props\n   * @param {ImporterOptions} options\n   */\n  constructor(props, options) {\n    super(props, options);\n    /** @type {Bucket<InProgressImportResult | Dir>} */\n\n    this._bucket = createHAMT({\n      hashFn: options.hamtHashFn,\n      bits: options.hamtBucketBits\n    });\n  }\n  /**\n   * @param {string} name\n   * @param {InProgressImportResult | Dir} value\n   */\n\n\n  async put(name, value) {\n    await this._bucket.put(name, value);\n  }\n  /**\n   * @param {string} name\n   */\n\n\n  get(name) {\n    return this._bucket.get(name);\n  }\n\n  childCount() {\n    return this._bucket.leafCount();\n  }\n\n  directChildrenCount() {\n    return this._bucket.childrenCount();\n  }\n\n  onlyChild() {\n    return this._bucket.onlyChild();\n  }\n\n  async *eachChildSeries() {\n    for await (const {\n      key,\n      value\n    } of this._bucket.eachLeafSeries()) {\n      yield {\n        key,\n        child: value\n      };\n    }\n  }\n  /**\n   * @param {BlockAPI} block\n   * @returns {AsyncIterable<ImportResult>}\n   */\n\n\n  async *flush(block) {\n    for await (const entry of flush(this._bucket, block, this, this.options)) {\n      yield { ...entry,\n        path: this.path\n      };\n    }\n  }\n\n}\n\nmodule.exports = DirSharded;\n/**\n * @param {Bucket<?>} bucket\n * @param {BlockAPI} block\n * @param {*} shardRoot\n * @param {ImporterOptions} options\n * @returns {AsyncIterable<ImportResult>}\n */\n\nasync function* flush(bucket, block, shardRoot, options) {\n  const children = bucket._children;\n  const links = [];\n  let childrenSize = 0;\n\n  for (let i = 0; i < children.length; i++) {\n    const child = children.get(i);\n\n    if (!child) {\n      continue;\n    }\n\n    const labelPrefix = i.toString(16).toUpperCase().padStart(2, '0');\n\n    if (child instanceof Bucket) {\n      let shard;\n\n      for await (const subShard of await flush(child, block, null, options)) {\n        shard = subShard;\n      }\n\n      if (!shard) {\n        throw new Error('Could not flush sharded directory, no subshard found');\n      }\n\n      links.push(new DAGLink(labelPrefix, shard.size, shard.cid));\n      childrenSize += shard.size;\n    } else if (typeof child.value.flush === 'function') {\n      const dir = child.value;\n      let flushedDir;\n\n      for await (const entry of dir.flush(block)) {\n        flushedDir = entry;\n        yield flushedDir;\n      }\n\n      const label = labelPrefix + child.key;\n      links.push(new DAGLink(label, flushedDir.size, flushedDir.cid));\n      childrenSize += flushedDir.size;\n    } else {\n      const value = child.value;\n\n      if (!value.cid) {\n        continue;\n      }\n\n      const label = labelPrefix + child.key;\n      const size = value.size;\n      links.push(new DAGLink(label, size, value.cid));\n      childrenSize += size;\n    }\n  } // go-ipfs uses little endian, that's why we have to\n  // reverse the bit field before storing it\n\n\n  const data = Uint8Array.from(children.bitField().reverse());\n  const dir = new UnixFS({\n    type: 'hamt-sharded-directory',\n    data,\n    fanout: bucket.tableSize(),\n    hashType: options.hamtHashCode,\n    mtime: shardRoot && shardRoot.mtime,\n    mode: shardRoot && shardRoot.mode\n  });\n  const node = new DAGNode(dir.marshal(), links);\n  const buffer = node.serialize();\n  const cid = await persist(buffer, block, options);\n  const size = buffer.length + childrenSize;\n  yield {\n    cid,\n    unixfs: dir,\n    size\n  };\n}","map":null,"metadata":{},"sourceType":"script"}