{"ast":null,"code":"import fetch from 'cross-fetch';\nimport { importer } from 'ipfs-unixfs-importer';\nimport FormData from 'form-data';\nimport { v4 } from 'uuid';\n\nfunction _toPrimitive(input, hint) {\n  if (typeof input !== \"object\" || input === null) return input;\n  var prim = input[Symbol.toPrimitive];\n\n  if (prim !== undefined) {\n    var res = prim.call(input, hint || \"default\");\n    if (typeof res !== \"object\") return res;\n    throw new TypeError(\"@@toPrimitive must return a primitive value.\");\n  }\n\n  return (hint === \"string\" ? String : Number)(input);\n}\n\nfunction _toPropertyKey(arg) {\n  var key = _toPrimitive(arg, \"string\");\n\n  return typeof key === \"symbol\" ? key : String(key);\n}\n\nfunction _defineProperty(obj, key, value) {\n  key = _toPropertyKey(key);\n\n  if (key in obj) {\n    Object.defineProperty(obj, key, {\n      value: value,\n      enumerable: true,\n      configurable: true,\n      writable: true\n    });\n  } else {\n    obj[key] = value;\n  }\n\n  return obj;\n}\n/**\n * @internal\n */\n\n\nconst DEFAULT_GATEWAY_URLS = {\n  // Note: Gateway URLs should have trailing slashes (we clean this on user input)\n  \"ipfs://\": [\"https://ipfs.thirdwebcdn.com/ipfs/\", \"https://cloudflare-ipfs.com/ipfs/\", \"https://ipfs.io/ipfs/\"]\n};\n/**\n * @internal\n */\n\nconst TW_IPFS_SERVER_URL = \"https://upload.nftlabs.co\";\n/**\n * @internal\n */\n\nconst PINATA_IPFS_URL = `https://api.pinata.cloud/pinning/pinFileToIPFS`;\n/**\n * @internal\n */\n\nfunction parseGatewayUrls(gatewayUrls) {\n  if (Array.isArray(gatewayUrls)) {\n    return {\n      \"ipfs://\": gatewayUrls\n    };\n  }\n\n  return gatewayUrls || {};\n}\n/**\n * @internal\n */\n\n\nfunction prepareGatewayUrls(gatewayUrls) {\n  const allGatewayUrls = { ...gatewayUrls,\n    ...DEFAULT_GATEWAY_URLS\n  };\n\n  for (const key of Object.keys(DEFAULT_GATEWAY_URLS)) {\n    if (gatewayUrls && gatewayUrls[key]) {\n      // Make sure that all user gateway URLs have trailing slashes\n      const cleanedGatewayUrls = gatewayUrls[key].map(url => url.replace(/\\/$/, \"\") + \"/\");\n      allGatewayUrls[key] = [...cleanedGatewayUrls, ...DEFAULT_GATEWAY_URLS[key]];\n    }\n  }\n\n  return allGatewayUrls;\n}\n/**\n * @internal\n */\n\n\nfunction isBrowser() {\n  return \"object\" !== \"undefined\";\n}\n/**\n * @internal\n */\n\n\nfunction isFileInstance(data) {\n  return global.File && data instanceof File;\n}\n/**\n * @internal\n */\n\n\nfunction isBufferInstance(data) {\n  return global.Buffer && data instanceof Buffer;\n}\n/**\n * @internal\n */\n\n\nfunction isBufferOrStringWithName(data) {\n  return !!(data && data.name && data.data && typeof data.name === \"string\" && (typeof data.data === \"string\" || isBufferInstance(data.data)));\n}\n\nfunction isFileOrBuffer(data) {\n  return isFileInstance(data) || isBufferInstance(data) || isBufferOrStringWithName(data);\n}\n/**\n * @internal\n */\n\n\nfunction isFileBufferOrStringEqual(input1, input2) {\n  if (isFileInstance(input1) && isFileInstance(input2)) {\n    // if both are File types, compare the name, size, and last modified date (best guess that these are the same files)\n    if (input1.name === input2.name && input1.lastModified === input2.lastModified && input1.size === input2.size) {\n      return true;\n    }\n  } else if (isBufferInstance(input1) && isBufferInstance(input2)) {\n    // buffer gives us an easy way to compare the contents!\n    return input1.equals(input2);\n  } else if (isBufferOrStringWithName(input1) && isBufferOrStringWithName(input2)) {\n    // first check the names\n    if (input1.name === input2.name) {\n      // if the data for both is a string, compare the strings\n      if (typeof input1.data === \"string\" && typeof input2.data === \"string\") {\n        return input1.data === input2.data;\n      } else if (isBufferInstance(input1.data) && isBufferInstance(input2.data)) {\n        // otherwise we know it's buffers, so compare the buffers\n        return input1.data.equals(input2.data);\n      }\n    }\n  } // otherwise if we have not found a match, return false\n\n\n  return false;\n}\n/**\n * @internal\n */\n\n\nfunction replaceGatewayUrlWithScheme(uri, gatewayUrls) {\n  for (const scheme of Object.keys(gatewayUrls)) {\n    for (const url of gatewayUrls[scheme]) {\n      if (uri.startsWith(url)) {\n        return uri.replace(url, scheme);\n      }\n    }\n  }\n\n  return uri;\n}\n/**\n * @internal\n */\n\n\nfunction replaceSchemeWithGatewayUrl(uri, gatewayUrls) {\n  let index = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 0;\n  const scheme = Object.keys(gatewayUrls).find(s => uri.startsWith(s));\n  const schemeGatewayUrls = scheme ? gatewayUrls[scheme] : [];\n\n  if (!scheme && index > 0 || scheme && index >= schemeGatewayUrls.length) {\n    return undefined;\n  }\n\n  if (!scheme) {\n    return uri;\n  }\n\n  return uri.replace(scheme, schemeGatewayUrls[index]);\n}\n/**\n * @internal\n */\n\n\nfunction replaceObjectGatewayUrlsWithSchemes(data, gatewayUrls) {\n  if (typeof data === \"string\") {\n    return replaceGatewayUrlWithScheme(data, gatewayUrls);\n  }\n\n  if (typeof data === \"object\") {\n    if (!data) {\n      return data;\n    }\n\n    if (isFileOrBuffer(data)) {\n      return data;\n    }\n\n    if (Array.isArray(data)) {\n      return data.map(entry => replaceObjectGatewayUrlsWithSchemes(entry, gatewayUrls));\n    }\n\n    return Object.fromEntries(Object.entries(data).map(_ref => {\n      let [key, value] = _ref;\n      return [key, replaceObjectGatewayUrlsWithSchemes(value, gatewayUrls)];\n    }));\n  }\n\n  return data;\n}\n/**\n * @internal\n */\n\n\nfunction replaceObjectSchemesWithGatewayUrls(data, gatewayUrls) {\n  if (typeof data === \"string\") {\n    return replaceSchemeWithGatewayUrl(data, gatewayUrls);\n  }\n\n  if (typeof data === \"object\") {\n    if (!data) {\n      return data;\n    }\n\n    if (isFileOrBuffer(data)) {\n      return data;\n    }\n\n    if (Array.isArray(data)) {\n      return data.map(entry => replaceObjectSchemesWithGatewayUrls(entry, gatewayUrls));\n    }\n\n    return Object.fromEntries(Object.entries(data).map(_ref2 => {\n      let [key, value] = _ref2;\n      return [key, replaceObjectSchemesWithGatewayUrls(value, gatewayUrls)];\n    }));\n  }\n\n  return data;\n}\n/**\n * @internal\n */\n\n\nfunction extractObjectFiles(data) {\n  let files = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : []; // If item is a FileOrBuffer add it to our list of files\n\n  if (isFileOrBuffer(data)) {\n    files.push(data);\n    return files;\n  }\n\n  if (typeof data === \"object\") {\n    if (!data) {\n      return files;\n    }\n\n    if (Array.isArray(data)) {\n      data.forEach(entry => extractObjectFiles(entry, files));\n    } else {\n      Object.keys(data).map(key => extractObjectFiles(data[key], files));\n    }\n  }\n\n  return files;\n}\n/**\n * @internal\n */\n\n\nfunction replaceObjectFilesWithUris(data, uris) {\n  if (isFileOrBuffer(data)) {\n    if (uris.length) {\n      data = uris.shift();\n      return data;\n    } else {\n      console.warn(\"Not enough URIs to replace all files in object.\");\n    }\n  }\n\n  if (typeof data === \"object\") {\n    if (!data) {\n      return data;\n    }\n\n    if (Array.isArray(data)) {\n      return data.map(entry => replaceObjectFilesWithUris(entry, uris));\n    } else {\n      return Object.fromEntries(Object.entries(data).map(_ref3 => {\n        let [key, value] = _ref3;\n        return [key, replaceObjectFilesWithUris(value, uris)];\n      }));\n    }\n  }\n\n  return data;\n}\n\nasync function getCIDForUpload(data, fileNames) {\n  let wrapWithDirectory = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : true;\n  let cidVersion = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : 0;\n  const contentWithPath = await Promise.all(data.map(async (file, i) => {\n    const path = fileNames[i];\n    let content;\n\n    if (typeof file === \"string\") {\n      content = new TextEncoder().encode(file);\n    } else if (isBufferOrStringWithName(file)) {\n      if (typeof file.data === \"string\") {\n        content = new TextEncoder().encode(file.data);\n      } else {\n        content = file.data;\n      }\n    } else if (Buffer.isBuffer(file)) {\n      content = file;\n    } else {\n      const buffer = await file.arrayBuffer();\n      content = new Uint8Array(buffer);\n    }\n\n    return {\n      path,\n      content\n    };\n  }));\n  return getCID(contentWithPath, wrapWithDirectory, cidVersion);\n}\n\nasync function getCID(content) {\n  let wrapWithDirectory = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : true;\n  let cidVersion = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 0;\n  const options = {\n    onlyHash: true,\n    wrapWithDirectory,\n    cidVersion\n  };\n  const dummyBlockstore = {\n    put: async () => {}\n  };\n  let lastCid;\n\n  for await (const {\n    cid\n  } of importer(content, dummyBlockstore, options)) {\n    lastCid = cid;\n  }\n\n  return `${lastCid}`;\n}\n\nasync function isUploaded(cid) {\n  const res = await fetch(`${DEFAULT_GATEWAY_URLS[\"ipfs://\"][0]}${cid}`, {\n    method: \"HEAD\",\n    headers: {\n      // tell the gateway to skip fetching from origin in order to fail fast on 404s and just re-upload in those cases\n      \"x-skip-origin\": \"true\"\n    }\n  });\n  return res.ok;\n}\n/**\n * Default downloader used - handles downloading from all schemes specified in the gateway URLs configuration.\n *\n * @example\n * ```jsx\n * // Can instantiate the downloader with the default gateway URLs\n * const downloader = new StorageDownloader();\n * const storage = new ThirdwebStorage({ downloader });\n * ```\n *\n * @public\n */\n\n\nclass StorageDownloader {\n  async download(uri, gatewayUrls) {\n    let attempts = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 0;\n\n    if (attempts > 3) {\n      throw new Error(\"[FAILED_TO_DOWNLOAD_ERROR] Failed to download from URI - too many attempts failed.\");\n    } // Replace recognized scheme with the highest priority gateway URL that hasn't already been attempted\n\n\n    const resolvedUri = replaceSchemeWithGatewayUrl(uri, gatewayUrls, attempts); // If every gateway URL we know about for the designated scheme has been tried (via recursion) and failed, throw an error\n\n    if (!resolvedUri) {\n      throw new Error(\"[FAILED_TO_DOWNLOAD_ERROR] Unable to download from URI - all gateway URLs failed to respond.\");\n    }\n\n    const res = await fetch(resolvedUri); // If request to the current gateway fails, recursively try the next one we know about\n\n    if (res.status >= 500 || res.status === 403 || res.status === 408) {\n      console.warn(`Request to ${resolvedUri} failed with status ${res.status} - ${res.statusText}`);\n      return this.download(uri, gatewayUrls, attempts + 1);\n    }\n\n    return res;\n  }\n\n}\n/**\n * Default uploader used - handles uploading arbitrary data to IPFS\n *\n * @example\n * ```jsx\n * // Can instantiate the uploader with default configuration\n * const uploader = new StorageUploader();\n * const storage = new ThirdwebStorage({ uploader });\n *\n * // Or optionally, can pass configuration\n * const options = {\n *   // Upload objects with resolvable URLs\n *   uploadWithGatewayUrl: true,\n * }\n * const uploader = new StorageUploader(options);\n * const storage = new ThirdwebStorage({ uploader });\n * ```\n *\n * @public\n */\n\n\nclass IpfsUploader {\n  constructor(options) {\n    _defineProperty(this, \"uploadWithGatewayUrl\", void 0);\n\n    this.uploadWithGatewayUrl = options?.uploadWithGatewayUrl || false;\n  }\n\n  async uploadBatch(data, options) {\n    if (options?.uploadWithoutDirectory && data.length > 1) {\n      throw new Error(\"[UPLOAD_WITHOUT_DIRECTORY_ERROR] Cannot upload more than one file or object without directory!\");\n    }\n\n    const formData = new FormData();\n    const {\n      form,\n      fileNames\n    } = this.buildFormData(formData, data, options);\n\n    try {\n      const cid = await getCIDForUpload(data, fileNames.map(name => decodeURIComponent(name)), !options?.uploadWithoutDirectory);\n\n      if ((await isUploaded(cid)) && !options?.alwaysUpload) {\n        if (options?.onProgress) {\n          options?.onProgress({\n            progress: 100,\n            total: 100\n          });\n        }\n\n        if (options?.uploadWithoutDirectory) {\n          return [`ipfs://${cid}`];\n        } else {\n          return fileNames.map(name => `ipfs://${cid}/${name}`);\n        }\n      }\n    } catch {// no-op\n    }\n\n    {\n      return this.uploadBatchBrowser(form, fileNames, options);\n    }\n  }\n  /**\n   * Fetches a one-time-use upload token that can used to upload\n   * a file to storage.\n   *\n   * @returns - The one time use token that can be passed to the Pinata API.\n   */\n\n\n  async getUploadToken() {\n    const res = await fetch(`${TW_IPFS_SERVER_URL}/grant`, {\n      method: \"GET\",\n      headers: {\n        \"X-APP-NAME\": // eslint-disable-next-line turbo/no-undeclared-env-vars\n        process.env.NODE_ENV === \"test\" || !!process.env.CI ? \"Storage SDK CI\" : \"Storage SDK\"\n      }\n    });\n\n    if (!res.ok) {\n      throw new Error(`Failed to get upload token`);\n    }\n\n    const body = await res.text();\n    return body;\n  }\n\n  buildFormData(form, files, options) {\n    const fileNameToFileMap = new Map();\n    const fileNames = [];\n\n    for (let i = 0; i < files.length; i++) {\n      const file = files[i];\n      let fileName = \"\";\n      let fileData = file;\n\n      if (isFileInstance(file)) {\n        if (options?.rewriteFileNames) {\n          let extensions = \"\";\n\n          if (file.name) {\n            const extensionStartIndex = file.name.lastIndexOf(\".\");\n\n            if (extensionStartIndex > -1) {\n              extensions = file.name.substring(extensionStartIndex);\n            }\n          }\n\n          fileName = `${i + options.rewriteFileNames.fileStartNumber}${extensions}`;\n        } else {\n          fileName = `${file.name}`;\n        }\n      } else if (isBufferOrStringWithName(file)) {\n        fileData = file.data;\n\n        if (options?.rewriteFileNames) {\n          fileName = `${i + options.rewriteFileNames.fileStartNumber}`;\n        } else {\n          fileName = `${file.name}`;\n        }\n      } else {\n        if (options?.rewriteFileNames) {\n          fileName = `${i + options.rewriteFileNames.fileStartNumber}`;\n        } else {\n          fileName = `${i}`;\n        }\n      } // If we don't want to wrap with directory, adjust the filepath\n\n\n      const filepath = options?.uploadWithoutDirectory ? `files` : `files/${fileName}`;\n\n      if (fileNameToFileMap.has(fileName)) {\n        // if the file in the map is the same as the file we are already looking at then just skip and continue\n        if (isFileBufferOrStringEqual(fileNameToFileMap.get(fileName), file)) {\n          // we add it to the filenames array so that we can return the correct number of urls,\n          fileNames.push(fileName); // but then we skip because we don't need to upload it multiple times\n\n          continue;\n        } // otherwise if file names are the same but they are not the same file then we should throw an error (trying to upload to differnt files but with the same names)\n\n\n        throw new Error(`[DUPLICATE_FILE_NAME_ERROR] File name ${fileName} was passed for more than one different file.`);\n      } // add it to the map so that we can check for duplicates\n\n\n      fileNameToFileMap.set(fileName, file); // add it to the filenames array so that we can return the correct number of urls\n\n      fileNames.push(fileName);\n      {\n        // browser does blob things, filepath is parsed differently on browser vs node.\n        // pls pinata?\n        form.append(\"file\", new Blob([fileData]), filepath);\n      }\n    }\n\n    const metadata = {\n      name: `Storage SDK`,\n      keyvalues: { ...options?.metadata\n      }\n    };\n    form.append(\"pinataMetadata\", JSON.stringify(metadata));\n\n    if (options?.uploadWithoutDirectory) {\n      form.append(\"pinataOptions\", JSON.stringify({\n        wrapWithDirectory: false\n      }));\n    }\n\n    return {\n      form,\n      // encode the file names on the way out (which is what the upload backend expects)\n      fileNames: fileNames.map(fName => encodeURIComponent(fName))\n    };\n  }\n\n  async uploadBatchBrowser(form, fileNames, options) {\n    const token = await this.getUploadToken();\n    return new Promise((resolve, reject) => {\n      const xhr = new XMLHttpRequest();\n      let timer = setTimeout(() => {\n        xhr.abort();\n        reject(new Error(\"Request to upload timed out! No upload progress received in 30s\"));\n      }, 30000);\n      xhr.upload.addEventListener(\"loadstart\", () => {\n        console.log(`[${Date.now()}] [IPFS] Started`);\n      });\n      xhr.upload.addEventListener(\"progress\", event => {\n        console.log(`[IPFS] Progress Event ${event.loaded}/${event.total}`);\n        clearTimeout(timer);\n\n        if (event.loaded < event.total) {\n          timer = setTimeout(() => {\n            xhr.abort();\n            reject(new Error(\"Request to upload timed out! No upload progress received in 30s\"));\n          }, 30000);\n        } else {\n          console.log(`[${Date.now()}] [IPFS] Uploaded files. Waiting for response.`);\n        }\n\n        if (event.lengthComputable && options?.onProgress) {\n          options?.onProgress({\n            progress: event.loaded,\n            total: event.total\n          });\n        }\n      });\n      xhr.addEventListener(\"load\", () => {\n        console.log(`[${Date.now()}] [IPFS] Load`);\n        clearTimeout(timer);\n\n        if (xhr.status >= 200 && xhr.status < 300) {\n          let body;\n\n          try {\n            body = JSON.parse(xhr.responseText);\n          } catch (err) {\n            return reject(new Error(\"Failed to parse JSON from upload response\"));\n          }\n\n          const cid = body.IpfsHash;\n\n          if (!cid) {\n            throw new Error(\"Failed to get IPFS hash from upload response\");\n          }\n\n          if (options?.uploadWithoutDirectory) {\n            return resolve([`ipfs://${cid}`]);\n          } else {\n            return resolve(fileNames.map(name => `ipfs://${cid}/${name}`));\n          }\n        }\n\n        return reject(new Error(`Upload failed with status ${xhr.status} - ${xhr.responseText}`));\n      });\n      xhr.addEventListener(\"error\", () => {\n        console.log(\"[IPFS] Load\");\n        clearTimeout(timer);\n\n        if (xhr.readyState !== 0 && xhr.readyState !== 4 || xhr.status === 0) {\n          return reject(new Error(\"This looks like a network error, the endpoint might be blocked by an internet provider or a firewall.\"));\n        }\n\n        return reject(new Error(\"Unknown upload error occured\"));\n      });\n      xhr.open(\"POST\", PINATA_IPFS_URL);\n      xhr.setRequestHeader(\"Authorization\", `Bearer ${token}`);\n      xhr.send(form);\n    });\n  }\n\n  async uploadBatchNode(form, fileNames, options) {\n    const token = await this.getUploadToken();\n\n    if (options?.onProgress) {\n      console.warn(\"The onProgress option is only supported in the browser\");\n    }\n\n    const res = await fetch(PINATA_IPFS_URL, {\n      method: \"POST\",\n      headers: {\n        Authorization: `Bearer ${token}`,\n        ...form.getHeaders()\n      },\n      body: form.getBuffer()\n    });\n    const body = await res.json();\n\n    if (!res.ok) {\n      console.warn(body);\n      throw new Error(\"Failed to upload files to IPFS\");\n    }\n\n    const cid = body.IpfsHash;\n\n    if (!cid) {\n      throw new Error(\"Failed to upload files to IPFS\");\n    }\n\n    if (options?.uploadWithoutDirectory) {\n      return [`ipfs://${cid}`];\n    } else {\n      return fileNames.map(name => `ipfs://${cid}/${name}`);\n    }\n  }\n\n}\n/**\n * Upload and download files from decentralized storage systems.\n *\n * @example\n * ```jsx\n * // Create a default storage class without any configuration\n * const storage = new ThirdwebStorage();\n *\n * // Upload any file or JSON object\n * const uri = await storage.upload(data);\n * const result = await storage.download(uri);\n *\n * // Or configure a custom uploader, downloader, and gateway URLs\n * const gatewayUrls = {\n *   // We define a mapping of schemes to gateway URLs\n *   \"ipfs://\": [\n *     \"https://ipfs.thirdwebcdn.com/ipfs/\",\n *     \"https://cloudflare-ipfs.com/ipfs/\",\n *     \"https://ipfs.io/ipfs/\",\n *   ],\n * };\n * const downloader = new StorageDownloader();\n * const uploader = new IpfsUploader();\n * const storage = new ThirdwebStorage({ uploader, downloader, gatewayUrls });\n * ```\n *\n * @public\n */\n\n\nclass ThirdwebStorage {\n  constructor(options) {\n    _defineProperty(this, \"uploader\", void 0);\n\n    _defineProperty(this, \"downloader\", void 0);\n\n    _defineProperty(this, \"gatewayUrls\", void 0);\n\n    this.uploader = options?.uploader || new IpfsUploader();\n    this.downloader = options?.downloader || new StorageDownloader();\n    this.gatewayUrls = prepareGatewayUrls(parseGatewayUrls(options?.gatewayUrls));\n  }\n  /**\n   * Resolve any scheme on a URL to get a retrievable URL for the data\n   *\n   * @param url - The URL to resolve the scheme of\n   * @returns The URL with its scheme resolved\n   *\n   * @example\n   * ```jsx\n   * const uri = \"ipfs://example\";\n   * const url = storage.resolveScheme(uri);\n   * console.log(url);\n   * ```\n   */\n\n\n  resolveScheme(url) {\n    return replaceSchemeWithGatewayUrl(url, this.gatewayUrls);\n  }\n  /**\n   * Downloads arbitrary data from any URL scheme.\n   *\n   * @param url - The URL of the data to download\n   * @returns The response object fetched from the resolved URL\n   *\n   * @example\n   * ```jsx\n   * const uri = \"ipfs://example\";\n   * const data = await storage.download(uri);\n   * ```\n   */\n\n\n  async download(url) {\n    return this.downloader.download(url, this.gatewayUrls);\n  }\n  /**\n   * Downloads JSON data from any URL scheme.\n   * Resolves any URLs with schemes to retrievable gateway URLs.\n   *\n   * @param url - The URL of the JSON data to download\n   * @returns The JSON data fetched from the resolved URL\n   *\n   * @example\n   * ```jsx\n   * const uri = \"ipfs://example\";\n   * const json = await storage.downloadJSON(uri);\n   * ```\n   */\n\n\n  async downloadJSON(url) {\n    const res = await this.download(url); // If we get a JSON object, recursively replace any schemes with gatewayUrls\n\n    const json = await res.json();\n    return replaceObjectSchemesWithGatewayUrls(json, this.gatewayUrls);\n  }\n  /**\n   * Upload arbitrary file or JSON data using the configured decentralized storage system.\n   * Automatically uploads any file data within JSON objects and replaces them with hashes.\n   *\n   * @param data - Arbitrary file or JSON data to upload\n   * @param options - Options to pass through to the storage uploader class\n   * @returns - The URI of the uploaded data\n   *\n   * @example\n   * ```jsx\n   * // Upload file data\n   * const file = readFileSync(\"../file.jpg\");\n   * const fileUri = await storage.upload(file);\n   *\n   * // Or upload a JSON object\n   * const json = { name: \"JSON\", image: file };\n   * const jsonUri = await storage.upload(json);\n   * ```\n   */\n\n\n  async upload(data, options) {\n    const [uri] = await this.uploadBatch([data], options);\n    return uri;\n  }\n  /**\n   * Batch upload arbitrary file or JSON data using the configured decentralized storage system.\n   * Automatically uploads any file data within JSON objects and replaces them with hashes.\n   *\n   * @param data - Array of arbitrary file or JSON data to upload\n   * @param options - Options to pass through to the storage uploader class\n   * @returns - The URIs of the uploaded data\n   *\n   * @example\n   * ```jsx\n   * // Upload an array of file data\n   * const files = [\n   *  readFileSync(\"../file1.jpg\"),\n   *  readFileSync(\"../file2.jpg\"),\n   * ];\n   * const fileUris = await storage.uploadBatch(files);\n   *\n   * // Upload an array of JSON objects\n   * const objects = [\n   *  { name: \"JSON 1\", image: files[0] },\n   *  { name: \"JSON 2\", image: files[1] },\n   * ];\n   * const jsonUris = await storage.uploadBatch(objects);\n   * ```\n   */\n\n\n  async uploadBatch(data, options) {\n    data = data.filter(item => item !== undefined);\n\n    if (!data.length) {\n      return [];\n    }\n\n    const isFileArray = data.map(item => isFileOrBuffer(item) || typeof item === \"string\").every(item => !!item);\n    let uris = []; // If data is an array of files, pass it through to upload directly\n\n    if (isFileArray) {\n      uris = await this.uploader.uploadBatch(data, options);\n    } else {\n      // Otherwise it is an array of JSON objects, so we have to prepare it first\n      const metadata = (await this.uploadAndReplaceFilesWithHashes(data, options)).map(item => {\n        if (typeof item === \"string\") {\n          return item;\n        }\n\n        return JSON.stringify(item);\n      });\n      uris = await this.uploader.uploadBatch(metadata, options);\n    }\n\n    if (options?.uploadWithGatewayUrl || this.uploader.uploadWithGatewayUrl) {\n      return uris.map(uri => this.resolveScheme(uri));\n    } else {\n      return uris;\n    }\n  }\n\n  async uploadAndReplaceFilesWithHashes(data, options) {\n    let cleaned = data; // Replace any gateway URLs with their hashes\n\n    cleaned = replaceObjectGatewayUrlsWithSchemes(cleaned, this.gatewayUrls); // Recurse through data and extract files to upload\n\n    const files = extractObjectFiles(cleaned);\n\n    if (files.length) {\n      // Upload all files that came from the object\n      const uris = await this.uploader.uploadBatch(files, options); // Recurse through data and replace files with hashes\n\n      cleaned = replaceObjectFilesWithUris(cleaned, uris);\n    }\n\n    if (options?.uploadWithGatewayUrl || this.uploader.uploadWithGatewayUrl) {\n      // If flag is set, replace all schemes with their preferred gateway URL\n      // Ex: used for Solana, where services don't resolve schemes for you, so URLs must be usable by default\n      cleaned = replaceObjectSchemesWithGatewayUrls(cleaned, this.gatewayUrls);\n    }\n\n    return cleaned;\n  }\n\n}\n/**\n * @internal\n */\n\n\nclass MockDownloader {\n  constructor(storage) {\n    _defineProperty(this, \"gatewayUrls\", DEFAULT_GATEWAY_URLS);\n\n    _defineProperty(this, \"storage\", void 0);\n\n    this.storage = storage;\n  }\n\n  async download(url) {\n    const [cid, name] = url.includes(\"mock://\") ? url.replace(\"mock://\", \"\").split(\"/\") : url.replace(\"ipfs://\", \"\").split(\"/\");\n    const data = name ? this.storage[cid][name] : this.storage[cid];\n    return {\n      async json() {\n        return Promise.resolve(JSON.parse(data));\n      },\n\n      async text() {\n        return Promise.resolve(data);\n      }\n\n    };\n  }\n\n}\n/**\n * @internal\n */\n\n\nclass MockUploader {\n  constructor(storage) {\n    _defineProperty(this, \"storage\", void 0);\n\n    this.storage = storage;\n  }\n\n  async uploadBatch(data, options) {\n    const cid = v4();\n    const uris = [];\n    this.storage[cid] = {};\n    let index = options?.rewriteFileNames?.fileStartNumber || 0;\n\n    for (const file of data) {\n      let contents;\n\n      if (isFileInstance(file)) {\n        contents = await file.text();\n      } else if (isBufferInstance(file)) {\n        contents = file.toString();\n      } else if (typeof file === \"string\") {\n        contents = file;\n      } else {\n        contents = isBufferInstance(file.data) ? file.data.toString() : file.data;\n        const name = file.name ? file.name : `file_${index}`;\n        this.storage[cid][name] = contents;\n        uris.push(`mock://${cid}/${name}`);\n        continue;\n      }\n\n      this.storage[cid][index.toString()] = contents;\n      uris.push(`mock://${cid}/${index}`);\n      index += 1;\n    }\n\n    return uris;\n  }\n\n}\n\nexport { DEFAULT_GATEWAY_URLS, IpfsUploader, MockDownloader, MockUploader, PINATA_IPFS_URL, StorageDownloader, TW_IPFS_SERVER_URL, ThirdwebStorage, extractObjectFiles, getCID, getCIDForUpload, isBrowser, isBufferInstance, isBufferOrStringWithName, isFileBufferOrStringEqual, isFileInstance, isFileOrBuffer, isUploaded, parseGatewayUrls, prepareGatewayUrls, replaceGatewayUrlWithScheme, replaceObjectFilesWithUris, replaceObjectGatewayUrlsWithSchemes, replaceObjectSchemesWithGatewayUrls, replaceSchemeWithGatewayUrl };","map":null,"metadata":{},"sourceType":"module"}